{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srai/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (1,4,7,17,26,29,49,60,62,79,86,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "business = pd.read_csv('yelp_academic_dataset_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets first start from a simple problem \n",
    "### Can we predict the star rating of a business based on some very simple business attributes such as location . The motivation behind this is that, often we will find examples where a business has not been rated by users, (for example new business). In cases like this it will be useful if we can predict a star rating based on some basic atributes of the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = business\n",
    "y = business['stars']\n",
    "X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = ['latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[X_train_index].as_matrix(numeric_columns)\n",
    "X_test = X.iloc[X_test_index].as_matrix(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "model_lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above scores suggest that Linear Regression model does not fit the data well, in fact it underfits. The training score is low, and the testing score is also low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets now add some non-numeric features to the model and see if the score improves. For doing this we need to identify non-numeric features which we beleive based on understanding of the problem will improve the prediction. As an example lets add all attributes of the business which provide information about the ambience, and also its price range. These attributes together with location might be good predictors for the star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_numeric_columns_ambience = [k for k in business.columns if 'Ambience' in k]\n",
    "feature_columns = ['latitude', 'longitude','attributes.Price Range']\n",
    "feature_columns.extend(non_numeric_columns_ambience)\n",
    "X = business\n",
    "y = business['stars']\n",
    "X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)\n",
    "X_train = X.iloc[X_train_index].fillna(-1).as_matrix(feature_columns)\n",
    "X_test = X.iloc[X_test_index].fillna(-1).as_matrix(feature_columns)\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "model_lr = lr.fit(X_train, y_train)\n",
    "print(\"Train Score = \", model_lr.score(X_train, y_train))\n",
    "print(\"Test Score = \", model_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Above attributes improve our R2 score very slightly for predicting the review count of a business based on its meta data attributes. Lets formalize this approach a bit, so that we can apply this more easily to other examples, and continue our search for better models to improve our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_columns_from_prefix(biz_df, prefix):\n",
    "    return [col for col in biz_df.columns if prefix in col]\n",
    "def eval_score(model, model_name, biz_df, numeric_col, other_col_prefix, y_col_name):\n",
    "    X = biz_df\n",
    "    y = biz_df[y_col_name]\n",
    "    feature_columns = copy.copy(numeric_col)\n",
    "    for col_prefix in other_col_prefix:\n",
    "        feature_columns.extend(get_columns_from_prefix(biz_df, col_prefix))\n",
    "    X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)    \n",
    "    X_train = X.iloc[X_train_index].fillna(0).as_matrix(feature_columns)\n",
    "    X_test = X.iloc[X_test_index].fillna(0).as_matrix(feature_columns)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print('Model Name : {0}, Train Score = {1}, Test Score = {2}, Train Set size = {3}'.format(model_name, train_score,test_score,X_train.shape))\n",
    "    return {\n",
    "        'X_train':X_train,\n",
    "        'X_test':X_test,\n",
    "        'y_train':y_train,\n",
    "        'y_test':y_test,\n",
    "        'model':model,\n",
    "        'train_score':train_score,\n",
    "        'test_score':test_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets run the same example from before with above functions to confirm results produced are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience']\n",
    "y_col_name = 'stars'\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "eval_res = eval_score(model, 'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation results are identical to previous run. Now lets add more features, and evaluate if it improves the model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair']\n",
    "y_col_name = 'stars'\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "eval_res = eval_score(model,'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition of more features improved the R2 score on test data slightly. Notice that we have not yet considered the category information while computing these models. Lets try adding the category infomration as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add all information available from categores as boolean variables. For example if a business has 'Mexican' as a category, we will add a columns to our data frame that will be True when 'Mexican' is a category present in the 'categories' column for that business. To compute this we will need to know the set of all categories first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_categories(business):\n",
    "    all_categories = pd.unique([item for sublist in business['categories'].apply(eval) for item in sublist])\n",
    "    for cat in all_categories:\n",
    "        business['computed.category.' + str(cat)] = business['categories'].apply(lambda x: True if cat in x else False)\n",
    "    return business\n",
    "business = add_categories(business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets compute new models now that use these additional columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.']\n",
    "y_col_name = 'stars'\n",
    "lr = LinearRegression()\n",
    "eval_res = eval_score(lr,'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The train score is  slightly greater than the test score,indicating overfitting in this linear regression model. Lets see if building a model that can capture the non-linearity and interactiion effects amongst the features. RandomForest and GradientBoosting approaches are both capable of acheiving this. We expect both the train and test scores to imrove as a result of using these models.   These models  takes a few minutes to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, max_depth = 12, verbose = 1,n_jobs = 4)\n",
    "eval_res = eval_score(rf,'Random Forest', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The random forest model above has lower score on both train data as well as test data. This suggests that the random forest as defined above is not able to fit the data in a manner comparable with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We continue to search for models that can capture the patterns in the data in a better manner. Lets continue to search for a model that improves the training and test scores beyond the Linear Regression model. Lets explore now if gradient boosting regression, another advanced regression technique can improve the fit by improving the score on our training, as well as test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 10,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting',business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above Gradient Boosting model improves both the training score as well as test score in comparision with the LinearRegression model. However there is a significant gap between the train and test scores. This indicates overfitting. At this stage we expect that reducing model complexity should not hurt the test score.  Lets reduce model complexity by reducing depth of individual trees in the ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 10,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting',business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As expected the gap between the test and train scores has reduced. However the test score has also reduced.  \n",
    "#### The best model for improving the scores on test data set so far, is the gradient boosted model with  individual trees in the ensamble grown to a depth of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try to bring in features into the model that also include user behavior. \n",
    "#### Does the prediction of a business star rating improve if we know the number of checkins to the business on different days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets get the check in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkin = pd.read_csv('yelp_academic_dataset_checkin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_info.9-0</th>\n",
       "      <th>checkin_info.9-1</th>\n",
       "      <th>checkin_info.9-2</th>\n",
       "      <th>checkin_info.9-3</th>\n",
       "      <th>checkin_info.9-4</th>\n",
       "      <th>checkin_info.9-5</th>\n",
       "      <th>checkin_info.9-6</th>\n",
       "      <th>checkin_info.20-2</th>\n",
       "      <th>checkin_info.20-3</th>\n",
       "      <th>checkin_info.20-0</th>\n",
       "      <th>...</th>\n",
       "      <th>checkin_info.6-1</th>\n",
       "      <th>checkin_info.6-0</th>\n",
       "      <th>checkin_info.3-1</th>\n",
       "      <th>checkin_info.18-6</th>\n",
       "      <th>checkin_info.18-5</th>\n",
       "      <th>checkin_info.18-4</th>\n",
       "      <th>checkin_info.18-3</th>\n",
       "      <th>checkin_info.18-2</th>\n",
       "      <th>checkin_info.18-1</th>\n",
       "      <th>checkin_info.18-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_info.9-0  checkin_info.9-1  checkin_info.9-2  checkin_info.9-3  \\\n",
       "0               NaN               NaN               NaN               NaN   \n",
       "1               NaN               NaN               NaN               NaN   \n",
       "2               NaN               NaN               NaN               1.0   \n",
       "3               NaN               1.0               NaN               NaN   \n",
       "4               NaN               NaN               NaN               NaN   \n",
       "\n",
       "   checkin_info.9-4  checkin_info.9-5  checkin_info.9-6  checkin_info.20-2  \\\n",
       "0               NaN               1.0               NaN                NaN   \n",
       "1               3.0               2.0               NaN                NaN   \n",
       "2               NaN               NaN               NaN                NaN   \n",
       "3               5.0               NaN               NaN                NaN   \n",
       "4               NaN               NaN               NaN                NaN   \n",
       "\n",
       "   checkin_info.20-3  checkin_info.20-0        ...          checkin_info.6-1  \\\n",
       "0                NaN                NaN        ...                       NaN   \n",
       "1                NaN                NaN        ...                       NaN   \n",
       "2                NaN                NaN        ...                       NaN   \n",
       "3                NaN                NaN        ...                       NaN   \n",
       "4                NaN                NaN        ...                       NaN   \n",
       "\n",
       "   checkin_info.6-0  checkin_info.3-1  checkin_info.18-6 checkin_info.18-5  \\\n",
       "0               NaN               NaN                NaN               NaN   \n",
       "1               NaN               NaN                NaN               NaN   \n",
       "2               NaN               NaN                NaN               NaN   \n",
       "3               NaN               NaN                NaN               NaN   \n",
       "4               NaN               NaN                NaN               NaN   \n",
       "\n",
       "   checkin_info.18-4  checkin_info.18-3  checkin_info.18-2  checkin_info.18-1  \\\n",
       "0                1.0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                1.0                2.0                1.0                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   checkin_info.18-0  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lets see if the prediction scores for star rating of a business can be improved if we also include the check in info as one of the predictors. Note that this attribute is a user interaction based attribute, and deviates slightly from our use case that a business was new. However this score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_checkin = business.merge(checkin, on = 'business_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.Ambience.divey</th>\n",
       "      <th>attributes.Dietary Restrictions.vegan</th>\n",
       "      <th>attributes.Happy Hour</th>\n",
       "      <th>hours.Thursday.open</th>\n",
       "      <th>attributes.Order at Counter</th>\n",
       "      <th>attributes.Hair Types Specialized In.africanamerican</th>\n",
       "      <th>attributes.Hair Types Specialized In.kids</th>\n",
       "      <th>attributes.BYOB</th>\n",
       "      <th>hours.Friday.open</th>\n",
       "      <th>attributes.Good For.latenight</th>\n",
       "      <th>...</th>\n",
       "      <th>checkin_info.6-1</th>\n",
       "      <th>checkin_info.6-0</th>\n",
       "      <th>checkin_info.3-1</th>\n",
       "      <th>checkin_info.18-6</th>\n",
       "      <th>checkin_info.18-5</th>\n",
       "      <th>checkin_info.18-4</th>\n",
       "      <th>checkin_info.18-3</th>\n",
       "      <th>checkin_info.18-2</th>\n",
       "      <th>checkin_info.18-1</th>\n",
       "      <th>checkin_info.18-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes.Ambience.divey attributes.Dietary Restrictions.vegan  \\\n",
       "0                     False                                   NaN   \n",
       "1                       NaN                                   NaN   \n",
       "2                       NaN                                   NaN   \n",
       "3                      True                                   NaN   \n",
       "4                       NaN                                   NaN   \n",
       "\n",
       "  attributes.Happy Hour hours.Thursday.open attributes.Order at Counter  \\\n",
       "0                   NaN               11:00                         NaN   \n",
       "1                  True                 NaN                         NaN   \n",
       "2                   NaN                 NaN                         NaN   \n",
       "3                 False               10:00                         NaN   \n",
       "4                   NaN               11:00                         NaN   \n",
       "\n",
       "  attributes.Hair Types Specialized In.africanamerican  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  attributes.Hair Types Specialized In.kids attributes.BYOB hours.Friday.open  \\\n",
       "0                                       NaN             NaN             11:00   \n",
       "1                                       NaN             NaN               NaN   \n",
       "2                                       NaN             NaN               NaN   \n",
       "3                                       NaN             NaN             10:00   \n",
       "4                                       NaN             NaN             11:00   \n",
       "\n",
       "  attributes.Good For.latenight        ...        checkin_info.6-1  \\\n",
       "0                         False        ...                     NaN   \n",
       "1                           NaN        ...                     NaN   \n",
       "2                           NaN        ...                     NaN   \n",
       "3                         False        ...                     NaN   \n",
       "4                           NaN        ...                     NaN   \n",
       "\n",
       "  checkin_info.6-0 checkin_info.3-1 checkin_info.18-6 checkin_info.18-5  \\\n",
       "0              NaN              NaN               NaN               NaN   \n",
       "1              NaN              NaN               NaN               NaN   \n",
       "2              NaN              NaN               NaN               NaN   \n",
       "3              NaN              NaN               NaN               NaN   \n",
       "4              NaN              NaN               NaN               NaN   \n",
       "\n",
       "  checkin_info.18-4 checkin_info.18-3 checkin_info.18-2 checkin_info.18-1  \\\n",
       "0               NaN               NaN               NaN               NaN   \n",
       "1               NaN               NaN               NaN               NaN   \n",
       "2               1.0               NaN               NaN               NaN   \n",
       "3               NaN               NaN               NaN               NaN   \n",
       "4               NaN               NaN               NaN               NaN   \n",
       "\n",
       "  checkin_info.18-0  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 1284 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_checkin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add all the 'checkin_info' from the business_checkin data frame as features into the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.', 'checkin_info']\n",
    "y_col_name = 'stars'\n",
    "lr = LinearRegression()\n",
    "eval_res = eval_score(lr, 'LinearRegression', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets also evaluate the model scores when we train the gradient boosting configuration from previous examples that gave us better scores than other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 10,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far the R2 score of 0.24637636022509302 is the best we have for predicting a business's star rating using its meta data, and check in info. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets change our problem definition slightly, to see if this problem can be solved as a classification problem. \n",
    "#### Lets try to predict now whether a business has a 'Good Score' or 'Bad Score' based on its meta data and check in info or not \n",
    "#### We define a 'Good Score' for business to be any star rating > 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_checkin['good_score'] = business_checkin['stars'].apply(lambda x: x > 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression model on this, and lets create the first classification model using only business meta data as its features (i.e not including checkin info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LogisticRegression, Train Score = 0.8451688009313155, Test Score = 0.8382515569524475, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.']\n",
    "y_col_name = 'good_score'\n",
    "lr = LogisticRegression()\n",
    "eval_res = eval_score(lr, 'LogisticRegression', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The scores above are high, but can be mis-leading, lets compute the precision recall curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117ccad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "y_score = lr.decision_function(eval_res['X_test'])\n",
    "y_test = eval_res['y_test']\n",
    "precision, recall, threshold = precision_recall_curve(y_test,y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "plt.clf()\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An AUC of 0.94 as above, indicates that the model fits the data well, by choosing appropriate threshold for predicton we can achieve the desired precision, as well as recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cf = pd.DataFrame({'precision':precision[1:], 'recall':recall[1:], 'threshold':threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>0.850003</td>\n",
       "      <td>0.978238</td>\n",
       "      <td>-0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.850018</td>\n",
       "      <td>0.977958</td>\n",
       "      <td>0.008895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.850070</td>\n",
       "      <td>0.977958</td>\n",
       "      <td>0.008918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.850061</td>\n",
       "      <td>0.977888</td>\n",
       "      <td>0.009083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.850113</td>\n",
       "      <td>0.977888</td>\n",
       "      <td>0.009409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.850103</td>\n",
       "      <td>0.977818</td>\n",
       "      <td>0.009525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.850155</td>\n",
       "      <td>0.977818</td>\n",
       "      <td>0.010660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>0.850146</td>\n",
       "      <td>0.977748</td>\n",
       "      <td>0.010797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.850137</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.850189</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.850240</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>0.012347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.850292</td>\n",
       "      <td>0.977678</td>\n",
       "      <td>0.012922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.850283</td>\n",
       "      <td>0.977608</td>\n",
       "      <td>0.013148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>0.850335</td>\n",
       "      <td>0.977608</td>\n",
       "      <td>0.013149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.850326</td>\n",
       "      <td>0.977538</td>\n",
       "      <td>0.014319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.850377</td>\n",
       "      <td>0.977538</td>\n",
       "      <td>0.014468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.850368</td>\n",
       "      <td>0.977468</td>\n",
       "      <td>0.015086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.850359</td>\n",
       "      <td>0.977398</td>\n",
       "      <td>0.016766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.850350</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.016859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.850341</td>\n",
       "      <td>0.977258</td>\n",
       "      <td>0.021570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.850393</td>\n",
       "      <td>0.977258</td>\n",
       "      <td>0.022009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.850384</td>\n",
       "      <td>0.977188</td>\n",
       "      <td>0.025346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.850435</td>\n",
       "      <td>0.977188</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.850487</td>\n",
       "      <td>0.977188</td>\n",
       "      <td>0.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.850478</td>\n",
       "      <td>0.977118</td>\n",
       "      <td>0.028924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.850469</td>\n",
       "      <td>0.977048</td>\n",
       "      <td>0.029770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.850460</td>\n",
       "      <td>0.976979</td>\n",
       "      <td>0.029810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.850451</td>\n",
       "      <td>0.976909</td>\n",
       "      <td>0.030248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0.850442</td>\n",
       "      <td>0.976839</td>\n",
       "      <td>0.031681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>0.850433</td>\n",
       "      <td>0.976769</td>\n",
       "      <td>0.031820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>0.890458</td>\n",
       "      <td>0.851515</td>\n",
       "      <td>1.039750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>0.890523</td>\n",
       "      <td>0.851515</td>\n",
       "      <td>1.039753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>0.890588</td>\n",
       "      <td>0.851515</td>\n",
       "      <td>1.039760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>0.890580</td>\n",
       "      <td>0.851445</td>\n",
       "      <td>1.039768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.851445</td>\n",
       "      <td>1.040236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>0.890638</td>\n",
       "      <td>0.851375</td>\n",
       "      <td>1.040374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3512</th>\n",
       "      <td>0.890630</td>\n",
       "      <td>0.851305</td>\n",
       "      <td>1.040559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>0.890622</td>\n",
       "      <td>0.851235</td>\n",
       "      <td>1.040859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>0.890614</td>\n",
       "      <td>0.851165</td>\n",
       "      <td>1.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>0.890606</td>\n",
       "      <td>0.851095</td>\n",
       "      <td>1.041108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>0.890598</td>\n",
       "      <td>0.851025</td>\n",
       "      <td>1.041173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>0.890590</td>\n",
       "      <td>0.850955</td>\n",
       "      <td>1.041266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>0.890582</td>\n",
       "      <td>0.850885</td>\n",
       "      <td>1.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>0.890574</td>\n",
       "      <td>0.850815</td>\n",
       "      <td>1.041706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>0.890639</td>\n",
       "      <td>0.850815</td>\n",
       "      <td>1.041808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>0.890631</td>\n",
       "      <td>0.850745</td>\n",
       "      <td>1.041889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>0.890623</td>\n",
       "      <td>0.850675</td>\n",
       "      <td>1.042156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>0.890688</td>\n",
       "      <td>0.850675</td>\n",
       "      <td>1.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>0.890753</td>\n",
       "      <td>0.850675</td>\n",
       "      <td>1.042306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>0.890745</td>\n",
       "      <td>0.850605</td>\n",
       "      <td>1.042312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>0.890737</td>\n",
       "      <td>0.850535</td>\n",
       "      <td>1.042349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>0.890729</td>\n",
       "      <td>0.850465</td>\n",
       "      <td>1.042415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>0.890794</td>\n",
       "      <td>0.850465</td>\n",
       "      <td>1.042593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>0.890786</td>\n",
       "      <td>0.850395</td>\n",
       "      <td>1.042756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>0.890778</td>\n",
       "      <td>0.850325</td>\n",
       "      <td>1.042791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>0.890770</td>\n",
       "      <td>0.850255</td>\n",
       "      <td>1.042899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>0.890762</td>\n",
       "      <td>0.850185</td>\n",
       "      <td>1.043033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>0.890828</td>\n",
       "      <td>0.850185</td>\n",
       "      <td>1.043365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>0.890820</td>\n",
       "      <td>0.850115</td>\n",
       "      <td>1.043591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>0.890812</td>\n",
       "      <td>0.850045</td>\n",
       "      <td>1.043592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2805 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall  threshold\n",
       "727    0.850003  0.978238  -0.002078\n",
       "732    0.850018  0.977958   0.008895\n",
       "733    0.850070  0.977958   0.008918\n",
       "734    0.850061  0.977888   0.009083\n",
       "735    0.850113  0.977888   0.009409\n",
       "736    0.850103  0.977818   0.009525\n",
       "737    0.850155  0.977818   0.010660\n",
       "738    0.850146  0.977748   0.010797\n",
       "739    0.850137  0.977678   0.011047\n",
       "740    0.850189  0.977678   0.011688\n",
       "741    0.850240  0.977678   0.012347\n",
       "742    0.850292  0.977678   0.012922\n",
       "743    0.850283  0.977608   0.013148\n",
       "744    0.850335  0.977608   0.013149\n",
       "745    0.850326  0.977538   0.014319\n",
       "746    0.850377  0.977538   0.014468\n",
       "747    0.850368  0.977468   0.015086\n",
       "748    0.850359  0.977398   0.016766\n",
       "749    0.850350  0.977328   0.016859\n",
       "750    0.850341  0.977258   0.021570\n",
       "751    0.850393  0.977258   0.022009\n",
       "752    0.850384  0.977188   0.025346\n",
       "753    0.850435  0.977188   0.027200\n",
       "754    0.850487  0.977188   0.028218\n",
       "755    0.850478  0.977118   0.028924\n",
       "756    0.850469  0.977048   0.029770\n",
       "757    0.850460  0.976979   0.029810\n",
       "758    0.850451  0.976909   0.030248\n",
       "759    0.850442  0.976839   0.031681\n",
       "760    0.850433  0.976769   0.031820\n",
       "...         ...       ...        ...\n",
       "3506   0.890458  0.851515   1.039750\n",
       "3507   0.890523  0.851515   1.039753\n",
       "3508   0.890588  0.851515   1.039760\n",
       "3509   0.890580  0.851445   1.039768\n",
       "3510   0.890646  0.851445   1.040236\n",
       "3511   0.890638  0.851375   1.040374\n",
       "3512   0.890630  0.851305   1.040559\n",
       "3513   0.890622  0.851235   1.040859\n",
       "3514   0.890614  0.851165   1.040874\n",
       "3515   0.890606  0.851095   1.041108\n",
       "3516   0.890598  0.851025   1.041173\n",
       "3517   0.890590  0.850955   1.041266\n",
       "3518   0.890582  0.850885   1.041700\n",
       "3519   0.890574  0.850815   1.041706\n",
       "3520   0.890639  0.850815   1.041808\n",
       "3521   0.890631  0.850745   1.041889\n",
       "3522   0.890623  0.850675   1.042156\n",
       "3523   0.890688  0.850675   1.042228\n",
       "3524   0.890753  0.850675   1.042306\n",
       "3525   0.890745  0.850605   1.042312\n",
       "3526   0.890737  0.850535   1.042349\n",
       "3527   0.890729  0.850465   1.042415\n",
       "3528   0.890794  0.850465   1.042593\n",
       "3529   0.890786  0.850395   1.042756\n",
       "3530   0.890778  0.850325   1.042791\n",
       "3531   0.890770  0.850255   1.042899\n",
       "3532   0.890762  0.850185   1.043033\n",
       "3533   0.890828  0.850185   1.043365\n",
       "3534   0.890820  0.850115   1.043591\n",
       "3535   0.890812  0.850045   1.043592\n",
       "\n",
       "[2805 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.query ('precision > 0.85 and recall > 0.85')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any of the threshold values from above table will yeild a precision and recall > 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
