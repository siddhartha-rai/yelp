{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm, grid_search, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srai/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (1,4,7,17,26,29,49,60,62,79,86,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "business = pd.read_csv('business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85901, 98)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attributes.Ambience.divey', 'attributes.Dietary Restrictions.vegan',\n",
       "       'attributes.Happy Hour', 'hours.Thursday.open',\n",
       "       'attributes.Order at Counter',\n",
       "       'attributes.Hair Types Specialized In.africanamerican',\n",
       "       'attributes.Hair Types Specialized In.kids', 'attributes.BYOB',\n",
       "       'hours.Friday.open', 'attributes.Good For.latenight',\n",
       "       'attributes.Outdoor Seating', 'attributes.Alcohol',\n",
       "       'attributes.Ambience.classy', 'attributes.By Appointment Only',\n",
       "       'attributes.Parking.lot', 'business_id', 'attributes.Ambience.touristy',\n",
       "       'attributes.Corkage', 'hours.Tuesday.open',\n",
       "       'attributes.Good For.brunch', 'categories', 'attributes.Waiter Service',\n",
       "       'hours.Monday.open', 'name', 'attributes.Parking.street',\n",
       "       'attributes.Ambience.hipster', 'attributes.BYOB/Corkage',\n",
       "       'attributes.Hair Types Specialized In.straightperms',\n",
       "       'attributes.Music.live', 'attributes.Dietary Restrictions.dairy-free',\n",
       "       'attributes.Music.background_music', 'attributes.Price Range',\n",
       "       'attributes.Good For.breakfast', 'attributes.Parking.garage',\n",
       "       'attributes.Music.karaoke', 'attributes.Good For Dancing',\n",
       "       'review_count', 'attributes.Hair Types Specialized In.asian', 'state',\n",
       "       'attributes.Accepts Credit Cards', 'hours.Friday.close',\n",
       "       'attributes.Good For.lunch', 'attributes.Parking.valet',\n",
       "       'attributes.Take-out', 'full_address', 'hours.Thursday.close',\n",
       "       'attributes.Hair Types Specialized In.coloring',\n",
       "       'attributes.Good For.dessert', 'attributes.Music.video',\n",
       "       'attributes.Dietary Restrictions.halal',\n",
       "       'attributes.Takes Reservations', 'hours.Saturday.open',\n",
       "       'attributes.Ages Allowed', 'attributes.Ambience.trendy',\n",
       "       'attributes.Delivery', 'hours.Wednesday.close', 'attributes.Wi-Fi',\n",
       "       'open', 'city', 'attributes.Wheelchair Accessible',\n",
       "       'attributes.Dietary Restrictions.gluten-free', 'stars',\n",
       "       'attributes.Dietary Restrictions.kosher', 'type', 'attributes.Caters',\n",
       "       'attributes.Ambience.intimate', 'latitude',\n",
       "       'attributes.Good For.dinner', 'attributes.Coat Check', 'longitude',\n",
       "       'hours.Monday.close', 'attributes.Hair Types Specialized In.extensions',\n",
       "       'hours.Tuesday.close', 'hours.Saturday.close',\n",
       "       'attributes.Good for Kids', 'attributes.Parking.validated',\n",
       "       'hours.Sunday.open', 'attributes.Accepts Insurance',\n",
       "       'attributes.Music.dj', 'attributes.Dietary Restrictions.soy-free',\n",
       "       'attributes.Has TV', 'hours.Sunday.close', 'attributes.Ambience.casual',\n",
       "       'attributes.Hair Types Specialized In.perms', 'attributes.Dogs Allowed',\n",
       "       'attributes.Drive-Thru', 'attributes.Dietary Restrictions.vegetarian',\n",
       "       'hours.Wednesday.open', 'attributes.Noise Level', 'attributes.Smoking',\n",
       "       'attributes.Attire', 'attributes.Hair Types Specialized In.curly',\n",
       "       'attributes.Good For Groups', 'neighborhoods',\n",
       "       'attributes.Open 24 Hours', 'attributes.Ambience.romantic',\n",
       "       'attributes.Music.jukebox', 'attributes.Ambience.upscale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.Ambience.divey</th>\n",
       "      <th>attributes.Dietary Restrictions.vegan</th>\n",
       "      <th>attributes.Happy Hour</th>\n",
       "      <th>hours.Thursday.open</th>\n",
       "      <th>attributes.Order at Counter</th>\n",
       "      <th>attributes.Hair Types Specialized In.africanamerican</th>\n",
       "      <th>attributes.Hair Types Specialized In.kids</th>\n",
       "      <th>attributes.BYOB</th>\n",
       "      <th>hours.Friday.open</th>\n",
       "      <th>attributes.Good For.latenight</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes.Noise Level</th>\n",
       "      <th>attributes.Smoking</th>\n",
       "      <th>attributes.Attire</th>\n",
       "      <th>attributes.Hair Types Specialized In.curly</th>\n",
       "      <th>attributes.Good For Groups</th>\n",
       "      <th>neighborhoods</th>\n",
       "      <th>attributes.Open 24 Hours</th>\n",
       "      <th>attributes.Ambience.romantic</th>\n",
       "      <th>attributes.Music.jukebox</th>\n",
       "      <th>attributes.Ambience.upscale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>casual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>average</td>\n",
       "      <td>no</td>\n",
       "      <td>casual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes.Ambience.divey attributes.Dietary Restrictions.vegan  \\\n",
       "0                     False                                   NaN   \n",
       "1                       NaN                                   NaN   \n",
       "2                       NaN                                   NaN   \n",
       "3                      True                                   NaN   \n",
       "4                       NaN                                   NaN   \n",
       "\n",
       "  attributes.Happy Hour hours.Thursday.open attributes.Order at Counter  \\\n",
       "0                   NaN               11:00                         NaN   \n",
       "1                  True                 NaN                         NaN   \n",
       "2                   NaN                 NaN                         NaN   \n",
       "3                 False               10:00                         NaN   \n",
       "4                   NaN               11:00                         NaN   \n",
       "\n",
       "  attributes.Hair Types Specialized In.africanamerican  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  attributes.Hair Types Specialized In.kids attributes.BYOB hours.Friday.open  \\\n",
       "0                                       NaN             NaN             11:00   \n",
       "1                                       NaN             NaN               NaN   \n",
       "2                                       NaN             NaN               NaN   \n",
       "3                                       NaN             NaN             10:00   \n",
       "4                                       NaN             NaN             11:00   \n",
       "\n",
       "  attributes.Good For.latenight             ...              \\\n",
       "0                         False             ...               \n",
       "1                           NaN             ...               \n",
       "2                           NaN             ...               \n",
       "3                         False             ...               \n",
       "4                           NaN             ...               \n",
       "\n",
       "  attributes.Noise Level attributes.Smoking attributes.Attire  \\\n",
       "0                average                NaN            casual   \n",
       "1                    NaN                NaN               NaN   \n",
       "2                    NaN                NaN               NaN   \n",
       "3                average                 no            casual   \n",
       "4                    NaN                NaN               NaN   \n",
       "\n",
       "  attributes.Hair Types Specialized In.curly attributes.Good For Groups  \\\n",
       "0                                        NaN                       True   \n",
       "1                                        NaN                       True   \n",
       "2                                        NaN                        NaN   \n",
       "3                                        NaN                       True   \n",
       "4                                        NaN                       True   \n",
       "\n",
       "  neighborhoods attributes.Open 24 Hours attributes.Ambience.romantic  \\\n",
       "0            []                      NaN                        False   \n",
       "1            []                      NaN                          NaN   \n",
       "2            []                      NaN                          NaN   \n",
       "3            []                      NaN                        False   \n",
       "4            []                      NaN                          NaN   \n",
       "\n",
       "  attributes.Music.jukebox attributes.Ambience.upscale  \n",
       "0                      NaN                       False  \n",
       "1                      NaN                         NaN  \n",
       "2                      NaN                         NaN  \n",
       "3                      NaN                       False  \n",
       "4                      NaN                         NaN  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To start with lets do some sanity checks on some of the attributes to confirm that there are sufficient dtaa points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    85901.000000\n",
       "mean        37.034786\n",
       "std          5.389208\n",
       "min         32.865882\n",
       "25%         33.506767\n",
       "50%         35.314392\n",
       "75%         36.203094\n",
       "max         56.033777\n",
       "Name: latitude, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['latitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    85901.000000\n",
       "mean       -99.107318\n",
       "std         27.437773\n",
       "min       -115.386550\n",
       "25%       -115.062628\n",
       "50%       -111.943739\n",
       "75%        -80.951101\n",
       "max          8.549249\n",
       "Name: longitude, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['longitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     27794\n",
       "unique        2\n",
       "top        True\n",
       "freq      24790\n",
       "Name: attributes.Good For Groups, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['attributes.Good For Groups'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity checks above reveal that some attributes like latitude, and longitude are available for all members of the data set, and other attributes such as 'attributes.Good For Groups' are available for almost a third of the dataset.  We are not including the sanity checks for other attributes in this notebook. In our modeling exercise, it may be good to ignore some attributes which are very sparse such as 'attributes.Dietary Restrictions.vegan'. However in this notebook we have not yet implemented the ability to exclude some attributes based on certain criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets take a simple problem \n",
    "#### Can we predict the star rating of a business based on some very simple business attributes such as location . The motivation behind this is that, often we will find examples where a business has not been rated by users, (for example new business). In cases like this it will be useful if we can predict a star rating based on some basic atributes of the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = business\n",
    "y = business['stars']\n",
    "X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_columns = ['latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X.iloc[X_train_index].as_matrix(numeric_columns)\n",
    "X_test = X.iloc[X_test_index].as_matrix(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "model_lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033301485390291319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00022648665467461804"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above scores suggest that Linear Regression model does not fit the data well, in fact it underfits. The training score is low, and the testing score is also low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets now add some non-numeric features to the model and see if the score improves. For doing this we need to identify non-numeric features which we beleive based on understanding of the problem will improve the prediction. As an example lets add all attributes of the business which provide information about the ambience, and also its price range. These attributes together with location might be good predictors for the star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.0141083917798\n",
      "Test Score =  0.0139446515319\n"
     ]
    }
   ],
   "source": [
    "non_numeric_columns_ambience = [k for k in business.columns if 'Ambience' in k]\n",
    "feature_columns = ['latitude', 'longitude','attributes.Price Range']\n",
    "feature_columns.extend(non_numeric_columns_ambience)\n",
    "X = business\n",
    "y = business['stars']\n",
    "X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)\n",
    "X_train = X.iloc[X_train_index].fillna(-1).as_matrix(feature_columns)\n",
    "X_test = X.iloc[X_test_index].fillna(-1).as_matrix(feature_columns)\n",
    "lr = sklearn.linear_model.LinearRegression()\n",
    "model_lr = lr.fit(X_train, y_train)\n",
    "print(\"Train Score = \", model_lr.score(X_train, y_train))\n",
    "print(\"Test Score = \", model_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Above attributes improve our R2 score very slightly for predicting the review count of a business based on its meta data attributes. Lets formalize this approach a bit, so that we can apply this more easily to other examples, and continue our search for better models to improve our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_columns_from_prefix(biz_df, prefix):\n",
    "    return [col for col in biz_df.columns if prefix in col]\n",
    "def eval_score(model, model_name, biz_df, numeric_col, other_col_prefix, y_col_name):\n",
    "    X = biz_df\n",
    "    y = biz_df[y_col_name]\n",
    "    feature_columns = copy.copy(numeric_col)\n",
    "    for col_prefix in other_col_prefix:\n",
    "        feature_columns.extend(get_columns_from_prefix(biz_df, col_prefix))\n",
    "    X_train_index,X_test_index,y_train,y_test = train_test_split(X.index,y,test_size=0.2, random_state = 1)    \n",
    "    X_train = X.iloc[X_train_index].fillna(0).as_matrix(feature_columns)\n",
    "    X_test = X.iloc[X_test_index].fillna(0).as_matrix(feature_columns)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    print('Model Name : {0}, Train Score = {1}, Test Score = {2}, Train Set size = {3}'.format(model_name, train_score,test_score,X_train.shape))\n",
    "    return {\n",
    "        'X_train':X_train,\n",
    "        'X_test':X_test,\n",
    "        'y_train':y_train,\n",
    "        'y_test':y_test,\n",
    "        'model':model,\n",
    "        'train_score':train_score,\n",
    "        'test_score':test_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets run the same example from before with above functions to confirm results produced are identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression, Train Score = 0.006101224860929788, Test Score = 0.006819635864603879, Train Set size = (68720, 12)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience']\n",
    "y_col_name = 'stars'\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "eval_res = eval_score(model, 'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation results are identical to previous run. Now lets add more features, and evaluate if it improves the model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression, Train Score = 0.03681422607497675, Test Score = 0.037212404973611224, Train Set size = (68720, 46)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair']\n",
    "y_col_name = 'stars'\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "eval_res = eval_score(model,'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition of more features improved the R2 score on test data slightly. Notice that we have not yet considered the category information while computing these models. Lets try adding the category infomration as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add all information available from categores as boolean variables. For example if a business has 'Mexican' as a category, we will add a columns to our data frame that will be True when 'Mexican' is a category present in the 'categories' column for that business. To compute this we will need to know the set of all categories first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_categories(business):\n",
    "    all_categories = pd.unique([item for sublist in business['categories'].apply(eval) for item in sublist])\n",
    "    for cat in all_categories:\n",
    "        business['computed.category.' + str(cat)] = business['categories'].apply(lambda x: True if cat in x else False)\n",
    "    return business\n",
    "business = add_categories(business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets compute new models now that use these additional columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression, Train Score = 0.25138468773889755, Test Score = 0.22334746185294585, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.']\n",
    "y_col_name = 'stars'\n",
    "lr = LinearRegression()\n",
    "eval_res = eval_score(lr,'LinearRegression', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The train score is  slightly greater than the test score,indicating overfitting in this linear regression model. Lets see if building a model that can capture the non-linearity and interactiion effects amongst the features. RandomForest and GradientBoosting approaches are both capable of acheiving this. We expect both the train and test scores to imrove as a result of using these models.   These models  takes a few minutes to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:   32.4s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : Random Forest, Train Score = 0.10923561524009928, Test Score = 0.09753894643746186, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=50, max_depth = 6, verbose = 1,n_jobs = 4)\n",
    "eval_res = eval_score(rf,'Random Forest', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The random forest model above has low score on both train data as well as test data. This suggests that the random forest as defined above is not able to fit the data in a manner comparable with Linear Regression. Lets us perform a grid serach using Cross Validation for best parameters. Please note this takes a few minutes to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : Random Forest, Train Score = 0.2126454261829409, Test Score = 0.16968005758541294, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators':[50, 100], 'max_depth':[6, 12], 'verbose':[1],'n_jobs':[4]}\n",
    "rf = RandomForestRegressor()\n",
    "clf = grid_search.GridSearchCV(rf, parameters)\n",
    "eval_res = eval_score(clf,'Random Forest', business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The grid search based on Cross Validation above has yeilded the best results so far. Let us now explore if any other modeling techniques can help improve our sciore further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets explore now if gradient boosting regression, another advanced regression technique can improve the fit by improving the score on our training, as well as test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8674           10.69m\n",
      "         2           0.8455           10.61m\n",
      "         3           0.8274           10.52m\n",
      "         4           0.8098           10.53m\n",
      "         5           0.7953           10.51m\n",
      "         6           0.7836           10.38m\n",
      "         7           0.7720           10.01m\n",
      "         8           0.7618            9.72m\n",
      "         9           0.7525            9.71m\n",
      "        10           0.7443            9.70m\n",
      "        11           0.7374            9.63m\n",
      "        12           0.7307            9.67m\n",
      "        13           0.7211            9.85m\n",
      "        14           0.7149            9.58m\n",
      "        15           0.7093            9.32m\n",
      "        16           0.7056            8.97m\n",
      "        17           0.7000            8.90m\n",
      "        18           0.6953            8.69m\n",
      "        19           0.6918            8.39m\n",
      "        20           0.6875            8.31m\n",
      "        21           0.6831            8.07m\n",
      "        22           0.6795            7.91m\n",
      "        23           0.6772            7.71m\n",
      "        24           0.6748            7.48m\n",
      "        25           0.6719            7.28m\n",
      "        26           0.6689            7.09m\n",
      "        27           0.6671            6.93m\n",
      "        28           0.6647            6.74m\n",
      "        29           0.6631            6.58m\n",
      "        30           0.6601            6.42m\n",
      "        31           0.6574            6.26m\n",
      "        32           0.6523            6.42m\n",
      "        33           0.6506            6.25m\n",
      "        34           0.6488            6.10m\n",
      "        35           0.6465            5.94m\n",
      "        36           0.6449            5.80m\n",
      "        37           0.6424            5.67m\n",
      "        38           0.6413            5.53m\n",
      "        39           0.6394            5.39m\n",
      "        40           0.6376            5.26m\n",
      "        41           0.6361            5.14m\n",
      "        42           0.6346            5.02m\n",
      "        43           0.6331            4.90m\n",
      "        44           0.6300            4.87m\n",
      "        45           0.6285            4.75m\n",
      "        46           0.6275            4.62m\n",
      "        47           0.6265            4.51m\n",
      "        48           0.6241            4.40m\n",
      "        49           0.6227            4.30m\n",
      "        50           0.6214            4.19m\n",
      "        51           0.6203            4.08m\n",
      "        52           0.6185            3.99m\n",
      "        53           0.6170            3.89m\n",
      "        54           0.6161            3.78m\n",
      "        55           0.6141            3.70m\n",
      "        56           0.6130            3.60m\n",
      "        57           0.6122            3.50m\n",
      "        58           0.6114            3.39m\n",
      "        59           0.6096            3.33m\n",
      "        60           0.6085            3.23m\n",
      "        61           0.6080            3.13m\n",
      "        62           0.6057            3.06m\n",
      "        63           0.6047            2.97m\n",
      "        64           0.6037            2.88m\n",
      "        65           0.6030            2.79m\n",
      "        66           0.6014            2.69m\n",
      "        67           0.6007            2.60m\n",
      "        68           0.6000            2.51m\n",
      "        69           0.5991            2.42m\n",
      "        70           0.5981            2.34m\n",
      "        71           0.5968            2.25m\n",
      "        72           0.5960            2.16m\n",
      "        73           0.5954            2.08m\n",
      "        74           0.5942            1.99m\n",
      "        75           0.5931            1.92m\n",
      "        76           0.5923            1.84m\n",
      "        77           0.5916            1.76m\n",
      "        78           0.5909            1.68m\n",
      "        79           0.5883            1.62m\n",
      "        80           0.5870            1.54m\n",
      "        81           0.5865            1.46m\n",
      "        82           0.5850            1.38m\n",
      "        83           0.5843            1.30m\n",
      "        84           0.5837            1.22m\n",
      "        85           0.5827            1.14m\n",
      "        86           0.5823            1.06m\n",
      "        87           0.5815           58.92s\n",
      "        88           0.5809           54.19s\n",
      "        89           0.5803           49.53s\n",
      "        90           0.5794           44.93s\n",
      "        91           0.5783           40.32s\n",
      "        92           0.5777           35.73s\n",
      "        93           0.5774           31.17s\n",
      "        94           0.5768           26.64s\n",
      "        95           0.5753           22.31s\n",
      "        96           0.5747           17.80s\n",
      "        97           0.5739           13.37s\n",
      "        98           0.5734            8.90s\n",
      "        99           0.5730            4.44s\n",
      "       100           0.5720            0.00s\n",
      "Model Name : Gradient Boosting, Train Score = 0.36096833735760625, Test Score = 0.23630548964743936, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth = 10,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting',business, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above Gradient Boosting model improves both the training score as well as test score in comparision with the LinearRegression model. However there is a significant gap between the train and test scores. This indicates overfitting. We should therefore explore approaches that reduce the variance. One way to achieve this with Gradient Boosting and other ensamble methods is by reducing the tree depth,  and increasing the number of estimators. We evaluate one such aproach towards the end of this notebook, since it takes longer to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best model for improving the scores on test data set so far, is the gradient boosted model with  individual trees in the ensamble grown to a depth of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets try to bring in features into the model that also include user behavior to complement the business meta data \n",
    "#### Does the prediction of a business star rating improve if we know the number of checkins to the business on different days?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets get the check in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkin = pd.read_csv('checkin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_info.9-0</th>\n",
       "      <th>checkin_info.9-1</th>\n",
       "      <th>checkin_info.9-2</th>\n",
       "      <th>checkin_info.9-3</th>\n",
       "      <th>checkin_info.9-4</th>\n",
       "      <th>checkin_info.9-5</th>\n",
       "      <th>checkin_info.9-6</th>\n",
       "      <th>checkin_info.20-2</th>\n",
       "      <th>checkin_info.20-3</th>\n",
       "      <th>checkin_info.20-0</th>\n",
       "      <th>...</th>\n",
       "      <th>checkin_info.6-1</th>\n",
       "      <th>checkin_info.6-0</th>\n",
       "      <th>checkin_info.3-1</th>\n",
       "      <th>checkin_info.18-6</th>\n",
       "      <th>checkin_info.18-5</th>\n",
       "      <th>checkin_info.18-4</th>\n",
       "      <th>checkin_info.18-3</th>\n",
       "      <th>checkin_info.18-2</th>\n",
       "      <th>checkin_info.18-1</th>\n",
       "      <th>checkin_info.18-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   checkin_info.9-0  checkin_info.9-1  checkin_info.9-2  checkin_info.9-3  \\\n",
       "0               NaN               NaN               NaN               NaN   \n",
       "1               NaN               NaN               NaN               NaN   \n",
       "2               NaN               NaN               NaN               1.0   \n",
       "3               NaN               1.0               NaN               NaN   \n",
       "4               NaN               NaN               NaN               NaN   \n",
       "\n",
       "   checkin_info.9-4  checkin_info.9-5  checkin_info.9-6  checkin_info.20-2  \\\n",
       "0               NaN               1.0               NaN                NaN   \n",
       "1               3.0               2.0               NaN                NaN   \n",
       "2               NaN               NaN               NaN                NaN   \n",
       "3               5.0               NaN               NaN                NaN   \n",
       "4               NaN               NaN               NaN                NaN   \n",
       "\n",
       "   checkin_info.20-3  checkin_info.20-0        ...          checkin_info.6-1  \\\n",
       "0                NaN                NaN        ...                       NaN   \n",
       "1                NaN                NaN        ...                       NaN   \n",
       "2                NaN                NaN        ...                       NaN   \n",
       "3                NaN                NaN        ...                       NaN   \n",
       "4                NaN                NaN        ...                       NaN   \n",
       "\n",
       "   checkin_info.6-0  checkin_info.3-1  checkin_info.18-6 checkin_info.18-5  \\\n",
       "0               NaN               NaN                NaN               NaN   \n",
       "1               NaN               NaN                NaN               NaN   \n",
       "2               NaN               NaN                NaN               NaN   \n",
       "3               NaN               NaN                NaN               NaN   \n",
       "4               NaN               NaN                NaN               NaN   \n",
       "\n",
       "   checkin_info.18-4  checkin_info.18-3  checkin_info.18-2  checkin_info.18-1  \\\n",
       "0                1.0                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                1.0                2.0                1.0                NaN   \n",
       "4                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   checkin_info.18-0  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Lets see if the prediction scores for star rating of a business can be improved if we also include the check in info as one of the predictors. Note that this attribute is a user interaction based attribute, and deviates slightly from our use case that a business was new. However this score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_checkin = business.merge(checkin, on = 'business_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes.Ambience.divey</th>\n",
       "      <th>attributes.Dietary Restrictions.vegan</th>\n",
       "      <th>attributes.Happy Hour</th>\n",
       "      <th>hours.Thursday.open</th>\n",
       "      <th>attributes.Order at Counter</th>\n",
       "      <th>attributes.Hair Types Specialized In.africanamerican</th>\n",
       "      <th>attributes.Hair Types Specialized In.kids</th>\n",
       "      <th>attributes.BYOB</th>\n",
       "      <th>hours.Friday.open</th>\n",
       "      <th>attributes.Good For.latenight</th>\n",
       "      <th>...</th>\n",
       "      <th>checkin_info.6-1</th>\n",
       "      <th>checkin_info.6-0</th>\n",
       "      <th>checkin_info.3-1</th>\n",
       "      <th>checkin_info.18-6</th>\n",
       "      <th>checkin_info.18-5</th>\n",
       "      <th>checkin_info.18-4</th>\n",
       "      <th>checkin_info.18-3</th>\n",
       "      <th>checkin_info.18-2</th>\n",
       "      <th>checkin_info.18-1</th>\n",
       "      <th>checkin_info.18-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  attributes.Ambience.divey attributes.Dietary Restrictions.vegan  \\\n",
       "0                     False                                   NaN   \n",
       "1                       NaN                                   NaN   \n",
       "2                       NaN                                   NaN   \n",
       "3                      True                                   NaN   \n",
       "4                       NaN                                   NaN   \n",
       "\n",
       "  attributes.Happy Hour hours.Thursday.open attributes.Order at Counter  \\\n",
       "0                   NaN               11:00                         NaN   \n",
       "1                  True                 NaN                         NaN   \n",
       "2                   NaN                 NaN                         NaN   \n",
       "3                 False               10:00                         NaN   \n",
       "4                   NaN               11:00                         NaN   \n",
       "\n",
       "  attributes.Hair Types Specialized In.africanamerican  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  attributes.Hair Types Specialized In.kids attributes.BYOB hours.Friday.open  \\\n",
       "0                                       NaN             NaN             11:00   \n",
       "1                                       NaN             NaN               NaN   \n",
       "2                                       NaN             NaN               NaN   \n",
       "3                                       NaN             NaN             10:00   \n",
       "4                                       NaN             NaN             11:00   \n",
       "\n",
       "  attributes.Good For.latenight        ...        checkin_info.6-1  \\\n",
       "0                         False        ...                     NaN   \n",
       "1                           NaN        ...                     NaN   \n",
       "2                           NaN        ...                     NaN   \n",
       "3                         False        ...                     NaN   \n",
       "4                           NaN        ...                     NaN   \n",
       "\n",
       "  checkin_info.6-0 checkin_info.3-1 checkin_info.18-6 checkin_info.18-5  \\\n",
       "0              NaN              NaN               NaN               NaN   \n",
       "1              NaN              NaN               NaN               NaN   \n",
       "2              NaN              NaN               NaN               NaN   \n",
       "3              NaN              NaN               NaN               NaN   \n",
       "4              NaN              NaN               NaN               NaN   \n",
       "\n",
       "  checkin_info.18-4 checkin_info.18-3 checkin_info.18-2 checkin_info.18-1  \\\n",
       "0               NaN               NaN               NaN               NaN   \n",
       "1               NaN               NaN               NaN               NaN   \n",
       "2               1.0               NaN               NaN               NaN   \n",
       "3               NaN               NaN               NaN               NaN   \n",
       "4               NaN               NaN               NaN               NaN   \n",
       "\n",
       "  checkin_info.18-0  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 1284 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_checkin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets add all the 'checkin_info' from the business_checkin data frame as features into the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression, Train Score = 0.25444365497076404, Test Score = 0.22425768482976072, Train Set size = (68720, 1246)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.', 'checkin_info']\n",
    "y_col_name = 'stars'\n",
    "lr = LinearRegression()\n",
    "eval_res = eval_score(lr, 'LinearRegression', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will try a gradient boosting approach on this towards the end of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets change our problem definition slightly, to see if this problem can be solved as a classification problem. \n",
    "#### Lets try to predict now whether a business has a 'Good Score' or 'Bad Score' based on its meta data and check in info or not \n",
    "#### We define a 'Good Score' for business to be any rating >= average (computed over the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_star_rating = eval_res['y_train'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.696711292200233"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_star_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_checkin['good_score'] = business_checkin['stars'].apply(lambda x: x >= mean_star_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression model on this, and create a classification model using only business meta data as its features (i.e not including checkin info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LogisticRegression, Train Score = 0.6922147846332946, Test Score = 0.6807519934811711, Train Set size = (68720, 1078)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.']\n",
    "y_col_name = 'good_score'\n",
    "lr = LogisticRegression()\n",
    "eval_res = eval_score(lr, 'LogisticRegression', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The scores above are high, but can be mis-leading, lets compute the precision recall curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121ac7470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "def plot_precision_recall(model, X_test, y_test):\n",
    "    y_score = model.decision_function(X_test)\n",
    "    precision, recall, threshold = precision_recall_curve(y_test,y_score)\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.clf()\n",
    "    plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()\n",
    "    return pd.DataFrame({'precision':precision[1:], 'recall':recall[1:], 'threshold':threshold})\n",
    "precision_recall_threshold = plot_precision_recall(lr, eval_res['X_test'], eval_res['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An AUC of 0.69 as above, indicates that the model fits the data reasonably well, by choosing appropriate threshold for predicton we can achieve the desired precision, as well as recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any of the threshold values from above table will yeild a precision and recall > 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>0.680004</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>-0.039632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>0.680080</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>-0.039563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201</th>\n",
       "      <td>0.680156</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>-0.039458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8202</th>\n",
       "      <td>0.680120</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>-0.038996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8203</th>\n",
       "      <td>0.680196</td>\n",
       "      <td>0.698980</td>\n",
       "      <td>-0.038929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall  threshold\n",
       "8199   0.680004  0.699095  -0.039632\n",
       "8200   0.680080  0.699095  -0.039563\n",
       "8201   0.680156  0.699095  -0.039458\n",
       "8202   0.680120  0.698980  -0.038996\n",
       "8203   0.680196  0.698980  -0.038929"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_threshold.query ('precision > 0.68 and recall > 0.68').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets include checkin infomration in this model, and evaluate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LogisticRegression, Train Score = 0.6522991850989522, Test Score = 0.6476922181479542, Train Set size = (68720, 1246)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.','checkin_info']\n",
    "y_col_name = 'good_score'\n",
    "lr = LogisticRegression()\n",
    "eval_res = eval_score(lr, 'LogisticRegression', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKxlCBERCSWEoSIiMRSghARkVj/H74bfmzLlYH/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121ab54a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_threshold = plot_precision_recall(lr, eval_res['X_test'], eval_res['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3638           13.66m\n",
      "         2           1.3462           13.42m\n",
      "         3           1.3297           13.96m\n",
      "         4           1.3156           14.18m\n",
      "         5           1.3036           14.24m\n",
      "         6           1.2913           14.15m\n",
      "         7           1.2802           14.00m\n",
      "         8           1.2706           14.17m\n",
      "         9           1.2616           14.22m\n",
      "        10           1.2533           14.19m\n",
      "        11           1.2457           14.19m\n",
      "        12           1.2395           13.89m\n",
      "        13           1.2329           13.73m\n",
      "        14           1.2267           13.62m\n",
      "        15           1.2220           13.31m\n",
      "        16           1.2154           13.18m\n",
      "        17           1.2111           13.04m\n",
      "        18           1.2080           12.59m\n",
      "        19           1.2042           12.43m\n",
      "        20           1.1998           12.28m\n",
      "        21           1.1966           11.99m\n",
      "        22           1.1938           11.72m\n",
      "        23           1.1913           11.39m\n",
      "        24           1.1889           11.05m\n",
      "        25           1.1869           10.70m\n",
      "        26           1.1837           10.52m\n",
      "        27           1.1813           10.33m\n",
      "        28           1.1796           10.03m\n",
      "        29           1.1775            9.77m\n",
      "        30           1.1757            9.51m\n",
      "        31           1.1744            9.22m\n",
      "        32           1.1725            9.00m\n",
      "        33           1.1707            8.86m\n",
      "        34           1.1683            8.66m\n",
      "        35           1.1669            8.43m\n",
      "        36           1.1642            8.26m\n",
      "        37           1.1622            8.05m\n",
      "        38           1.1606            7.86m\n",
      "        39           1.1593            7.66m\n",
      "        40           1.1577            7.50m\n",
      "        41           1.1557            7.34m\n",
      "        42           1.1534            7.19m\n",
      "        43           1.1519            7.03m\n",
      "        44           1.1496            6.90m\n",
      "        45           1.1483            6.72m\n",
      "        46           1.1460            6.63m\n",
      "        47           1.1446            6.46m\n",
      "        48           1.1432            6.28m\n",
      "        49           1.1420            6.11m\n",
      "        50           1.1395            5.98m\n",
      "        51           1.1381            5.83m\n",
      "        52           1.1370            5.68m\n",
      "        53           1.1357            5.53m\n",
      "        54           1.1343            5.38m\n",
      "        55           1.1315            5.29m\n",
      "        56           1.1298            5.16m\n",
      "        57           1.1266            5.11m\n",
      "        58           1.1257            4.97m\n",
      "        59           1.1242            4.84m\n",
      "        60           1.1231            4.70m\n",
      "        61           1.1211            4.59m\n",
      "        62           1.1202            4.44m\n",
      "        63           1.1185            4.31m\n",
      "        64           1.1175            4.17m\n",
      "        65           1.1166            4.03m\n",
      "        66           1.1153            3.91m\n",
      "        67           1.1142            3.77m\n",
      "        68           1.1134            3.64m\n",
      "        69           1.1125            3.52m\n",
      "        70           1.1112            3.40m\n",
      "        71           1.1102            3.28m\n",
      "        72           1.1081            3.18m\n",
      "        73           1.1069            3.06m\n",
      "        74           1.1055            2.94m\n",
      "        75           1.1033            2.83m\n",
      "        76           1.1024            2.70m\n",
      "        77           1.1015            2.58m\n",
      "        78           1.1007            2.45m\n",
      "        79           1.0997            2.34m\n",
      "        80           1.0988            2.22m\n",
      "        81           1.0982            2.10m\n",
      "        82           1.0974            1.98m\n",
      "        83           1.0964            1.87m\n",
      "        84           1.0950            1.76m\n",
      "        85           1.0944            1.64m\n",
      "        86           1.0925            1.54m\n",
      "        87           1.0911            1.43m\n",
      "        88           1.0900            1.32m\n",
      "        89           1.0889            1.21m\n",
      "        90           1.0873            1.10m\n",
      "        91           1.0861           59.21s\n",
      "        92           1.0857           52.40s\n",
      "        93           1.0848           45.79s\n",
      "        94           1.0841           39.09s\n",
      "        95           1.0835           32.55s\n",
      "        96           1.0823           26.07s\n",
      "        97           1.0817           19.55s\n",
      "        98           1.0812           13.00s\n",
      "        99           1.0800            6.51s\n",
      "       100           1.0795            0.00s\n",
      "Model Name : Gradient Boosting Classifier, Train Score = 0.7436117578579744, Test Score = 0.6837785926313952, Train Set size = (68720, 1246)\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingClassifier(n_estimators=100, max_depth = 8,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting Classifier', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niMSlBCEiInH9P8a6cnmVMrvqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1018db048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision_recall_threshold = plot_precision_recall(gbr, eval_res['X_test'], eval_res['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>0.680022</td>\n",
       "      <td>0.717658</td>\n",
       "      <td>0.033852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>0.680096</td>\n",
       "      <td>0.717658</td>\n",
       "      <td>0.034092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6976</th>\n",
       "      <td>0.680061</td>\n",
       "      <td>0.717543</td>\n",
       "      <td>0.034271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6977</th>\n",
       "      <td>0.680135</td>\n",
       "      <td>0.717543</td>\n",
       "      <td>0.034506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>0.680070</td>\n",
       "      <td>0.717085</td>\n",
       "      <td>0.035023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall  threshold\n",
       "6974   0.680022  0.717658   0.033852\n",
       "6975   0.680096  0.717658   0.034092\n",
       "6976   0.680061  0.717543   0.034271\n",
       "6977   0.680135  0.717543   0.034506\n",
       "6979   0.680070  0.717085   0.035023"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_threshold.query ('precision > 0.68 and recall > 0.68').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Gradient boosted model for regression with a depth of 300\n",
    "#### This takes a long time to generate, hence computing this at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : LinearRegression, Train Score = 0.25444365497076404, Test Score = 0.22425768482976072, Train Set size = (68720, 1246)\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8725           60.66m\n",
      "         2           0.8539           61.54m\n",
      "         3           0.8385           55.39m\n",
      "         4           0.8231           52.77m\n",
      "         5           0.8096           51.40m\n",
      "         6           0.7983           50.85m\n",
      "         7           0.7885           49.57m\n",
      "         8           0.7787           49.25m\n",
      "         9           0.7707           49.34m\n",
      "        10           0.7628           49.44m\n",
      "        11           0.7567           48.51m\n",
      "        12           0.7505           47.58m\n",
      "        13           0.7452           46.79m\n",
      "        14           0.7418           45.44m\n",
      "        15           0.7362           45.37m\n",
      "        16           0.7316           44.85m\n",
      "        17           0.7272           44.26m\n",
      "        18           0.7236           43.32m\n",
      "        19           0.7205           42.04m\n",
      "        20           0.7160           41.47m\n",
      "        21           0.7130           40.79m\n",
      "        22           0.7106           40.19m\n",
      "        23           0.7086           39.37m\n",
      "        24           0.7062           38.87m\n",
      "        25           0.7035           38.18m\n",
      "        26           0.7009           37.38m\n",
      "        27           0.6984           36.77m\n",
      "        28           0.6966           36.14m\n",
      "        29           0.6947           35.44m\n",
      "        30           0.6925           34.77m\n",
      "        31           0.6903           34.24m\n",
      "        32           0.6879           33.80m\n",
      "        33           0.6867           33.23m\n",
      "        34           0.6850           32.72m\n",
      "        35           0.6829           32.21m\n",
      "        36           0.6809           31.89m\n",
      "        37           0.6788           31.66m\n",
      "        38           0.6774           31.16m\n",
      "        39           0.6755           30.77m\n",
      "        40           0.6734           30.62m\n",
      "        41           0.6716           30.40m\n",
      "        42           0.6700           30.03m\n",
      "        43           0.6689           29.68m\n",
      "        44           0.6673           29.45m\n",
      "        45           0.6657           29.27m\n",
      "        46           0.6646           28.90m\n",
      "        47           0.6633           28.56m\n",
      "        48           0.6623           28.22m\n",
      "        49           0.6606           28.02m\n",
      "        50           0.6597           27.69m\n",
      "        51           0.6578           27.48m\n",
      "        52           0.6557           27.47m\n",
      "        53           0.6544           27.28m\n",
      "        54           0.6532           27.00m\n",
      "        55           0.6521           26.72m\n",
      "        56           0.6514           26.38m\n",
      "        57           0.6507           26.06m\n",
      "        58           0.6492           25.81m\n",
      "        59           0.6478           25.54m\n",
      "        60           0.6467           25.28m\n",
      "        61           0.6456           25.06m\n",
      "        62           0.6449           24.79m\n",
      "        63           0.6425           25.01m\n",
      "        64           0.6411           24.87m\n",
      "        65           0.6396           24.68m\n",
      "        66           0.6387           24.46m\n",
      "        67           0.6378           24.23m\n",
      "        68           0.6371           23.99m\n",
      "        69           0.6360           23.76m\n",
      "        70           0.6347           23.65m\n",
      "        71           0.6340           23.41m\n",
      "        72           0.6334           23.19m\n",
      "        73           0.6327           22.95m\n",
      "        74           0.6320           22.72m\n",
      "        75           0.6299           22.87m\n",
      "        76           0.6285           22.75m\n",
      "        77           0.6263           22.91m\n",
      "        78           0.6256           22.71m\n",
      "        79           0.6249           22.52m\n",
      "        80           0.6244           22.31m\n",
      "        81           0.6234           22.13m\n",
      "        82           0.6228           21.96m\n",
      "        83           0.6216           21.87m\n",
      "        84           0.6202           21.72m\n",
      "        85           0.6195           21.56m\n",
      "        86           0.6187           21.44m\n",
      "        87           0.6176           21.36m\n",
      "        88           0.6164           21.28m\n",
      "        89           0.6159           21.09m\n",
      "        90           0.6147           20.95m\n",
      "        91           0.6138           20.78m\n",
      "        92           0.6127           20.66m\n",
      "        93           0.6122           20.47m\n",
      "        94           0.6117           20.28m\n",
      "        95           0.6111           20.12m\n",
      "        96           0.6106           19.93m\n",
      "        97           0.6099           19.77m\n",
      "        98           0.6087           19.70m\n",
      "        99           0.6080           19.56m\n",
      "       100           0.6072           19.48m\n",
      "       101           0.6065           19.36m\n",
      "       102           0.6060           19.22m\n",
      "       103           0.6053           19.08m\n",
      "       104           0.6042           18.99m\n",
      "       105           0.6036           18.84m\n",
      "       106           0.6030           18.69m\n",
      "       107           0.6023           18.56m\n",
      "       108           0.6017           18.43m\n",
      "       109           0.6007           18.29m\n",
      "       110           0.6003           18.12m\n",
      "       111           0.5998           17.97m\n",
      "       112           0.5990           17.87m\n",
      "       113           0.5986           17.72m\n",
      "       114           0.5981           17.59m\n",
      "       115           0.5975           17.48m\n",
      "       116           0.5972           17.34m\n",
      "       117           0.5968           17.19m\n",
      "       118           0.5962           17.09m\n",
      "       119           0.5957           16.95m\n",
      "       120           0.5954           16.80m\n",
      "       121           0.5947           16.66m\n",
      "       122           0.5940           16.54m\n",
      "       123           0.5929           16.45m\n",
      "       124           0.5918           16.39m\n",
      "       125           0.5914           16.26m\n",
      "       126           0.5907           16.14m\n",
      "       127           0.5902           16.01m\n",
      "       128           0.5898           15.89m\n",
      "       129           0.5893           15.74m\n",
      "       130           0.5890           15.61m\n",
      "       131           0.5886           15.47m\n",
      "       132           0.5879           15.35m\n",
      "       133           0.5873           15.24m\n",
      "       134           0.5866           15.11m\n",
      "       135           0.5862           14.98m\n",
      "       136           0.5859           14.85m\n",
      "       137           0.5855           14.72m\n",
      "       138           0.5850           14.59m\n",
      "       139           0.5847           14.46m\n",
      "       140           0.5844           14.35m\n",
      "       141           0.5836           14.28m\n",
      "       142           0.5829           14.16m\n",
      "       143           0.5825           14.04m\n",
      "       144           0.5820           13.93m\n",
      "       145           0.5816           13.81m\n",
      "       146           0.5812           13.70m\n",
      "       147           0.5806           13.60m\n",
      "       148           0.5802           13.48m\n",
      "       149           0.5793           13.38m\n",
      "       150           0.5789           13.26m\n",
      "       151           0.5786           13.15m\n",
      "       152           0.5783           13.03m\n",
      "       153           0.5778           12.92m\n",
      "       154           0.5772           12.82m\n",
      "       155           0.5769           12.70m\n",
      "       156           0.5764           12.58m\n",
      "       157           0.5759           12.50m\n",
      "       158           0.5755           12.38m\n",
      "       159           0.5753           12.27m\n",
      "       160           0.5750           12.16m\n",
      "       161           0.5747           12.04m\n",
      "       162           0.5743           11.93m\n",
      "       163           0.5740           11.82m\n",
      "       164           0.5735           11.73m\n",
      "       165           0.5725           11.68m\n",
      "       166           0.5720           11.60m\n",
      "       167           0.5715           11.49m\n",
      "       168           0.5712           11.38m\n",
      "       169           0.5708           11.28m\n",
      "       170           0.5702           11.18m\n",
      "       171           0.5697           11.08m\n",
      "       172           0.5693           10.97m\n",
      "       173           0.5690           10.86m\n",
      "       174           0.5686           10.77m\n",
      "       175           0.5683           10.66m\n",
      "       176           0.5680           10.56m\n",
      "       177           0.5675           10.46m\n",
      "       178           0.5669           10.36m\n",
      "       179           0.5666           10.26m\n",
      "       180           0.5664           10.16m\n",
      "       181           0.5660           10.06m\n",
      "       182           0.5659            9.95m\n",
      "       183           0.5648            9.88m\n",
      "       184           0.5638            9.79m\n",
      "       185           0.5631            9.70m\n",
      "       186           0.5629            9.60m\n",
      "       187           0.5626            9.51m\n",
      "       188           0.5623            9.41m\n",
      "       189           0.5620            9.31m\n",
      "       190           0.5618            9.21m\n",
      "       191           0.5611            9.12m\n",
      "       192           0.5607            9.03m\n",
      "       193           0.5603            8.93m\n",
      "       194           0.5599            8.84m\n",
      "       195           0.5597            8.74m\n",
      "       196           0.5593            8.65m\n",
      "       197           0.5590            8.56m\n",
      "       198           0.5585            8.46m\n",
      "       199           0.5582            8.37m\n",
      "       200           0.5580            8.27m\n",
      "       201           0.5576            8.18m\n",
      "       202           0.5574            8.09m\n",
      "       203           0.5571            8.00m\n",
      "       204           0.5568            7.90m\n",
      "       205           0.5564            7.82m\n",
      "       206           0.5561            7.73m\n",
      "       207           0.5557            7.64m\n",
      "       208           0.5553            7.55m\n",
      "       209           0.5551            7.46m\n",
      "       210           0.5545            7.37m\n",
      "       211           0.5541            7.28m\n",
      "       212           0.5538            7.19m\n",
      "       213           0.5535            7.10m\n",
      "       214           0.5533            7.01m\n",
      "       215           0.5529            6.92m\n",
      "       216           0.5526            6.83m\n",
      "       217           0.5522            6.74m\n",
      "       218           0.5520            6.65m\n",
      "       219           0.5517            6.57m\n",
      "       220           0.5514            6.47m\n",
      "       221           0.5511            6.38m\n",
      "       222           0.5500            6.31m\n",
      "       223           0.5497            6.22m\n",
      "       224           0.5494            6.13m\n",
      "       225           0.5491            6.05m\n",
      "       226           0.5488            5.96m\n",
      "       227           0.5487            5.87m\n",
      "       228           0.5484            5.79m\n",
      "       229           0.5482            5.70m\n",
      "       230           0.5482            5.61m\n",
      "       231           0.5478            5.52m\n",
      "       232           0.5476            5.44m\n",
      "       233           0.5474            5.35m\n",
      "       234           0.5471            5.27m\n",
      "       235           0.5466            5.19m\n",
      "       236           0.5463            5.10m\n",
      "       237           0.5461            5.02m\n",
      "       238           0.5460            4.93m\n",
      "       239           0.5456            4.86m\n",
      "       240           0.5452            4.77m\n",
      "       241           0.5450            4.69m\n",
      "       242           0.5445            4.61m\n",
      "       243           0.5436            4.53m\n",
      "       244           0.5432            4.45m\n",
      "       245           0.5430            4.37m\n",
      "       246           0.5425            4.29m\n",
      "       247           0.5423            4.20m\n",
      "       248           0.5422            4.12m\n",
      "       249           0.5420            4.03m\n",
      "       250           0.5417            3.95m\n",
      "       251           0.5414            3.87m\n",
      "       252           0.5408            3.79m\n",
      "       253           0.5403            3.71m\n",
      "       254           0.5399            3.62m\n",
      "       255           0.5393            3.54m\n",
      "       256           0.5391            3.46m\n",
      "       257           0.5388            3.38m\n",
      "       258           0.5382            3.30m\n",
      "       259           0.5380            3.22m\n",
      "       260           0.5378            3.14m\n",
      "       261           0.5377            3.05m\n",
      "       262           0.5375            2.97m\n",
      "       263           0.5372            2.89m\n",
      "       264           0.5367            2.82m\n",
      "       265           0.5365            2.74m\n",
      "       266           0.5362            2.66m\n",
      "       267           0.5355            2.58m\n",
      "       268           0.5353            2.50m\n",
      "       269           0.5345            2.42m\n",
      "       270           0.5342            2.34m\n",
      "       271           0.5340            2.26m\n",
      "       272           0.5335            2.18m\n",
      "       273           0.5333            2.10m\n",
      "       274           0.5332            2.02m\n",
      "       275           0.5330            1.94m\n",
      "       276           0.5328            1.86m\n",
      "       277           0.5326            1.78m\n",
      "       278           0.5321            1.70m\n",
      "       279           0.5316            1.63m\n",
      "       280           0.5313            1.55m\n",
      "       281           0.5310            1.47m\n",
      "       282           0.5307            1.39m\n",
      "       283           0.5304            1.31m\n",
      "       284           0.5303            1.23m\n",
      "       285           0.5301            1.16m\n",
      "       286           0.5299            1.08m\n",
      "       287           0.5297            1.00m\n",
      "       288           0.5295           55.44s\n",
      "       289           0.5294           50.76s\n",
      "       290           0.5283           46.26s\n",
      "       291           0.5281           41.63s\n",
      "       292           0.5279           36.97s\n",
      "       293           0.5274           32.35s\n",
      "       294           0.5266           27.77s\n",
      "       295           0.5257           23.21s\n",
      "       296           0.5252           18.58s\n",
      "       297           0.5247           13.94s\n",
      "       298           0.5243            9.28s\n",
      "       299           0.5242            4.64s\n",
      "       300           0.5240            0.00s\n",
      "Model Name : Gradient Boosting, Train Score = 0.4146619999068768, Test Score = 0.25615626895582, Train Set size = (68720, 1246)\n"
     ]
    }
   ],
   "source": [
    "numeric_col_names = ['latitude', 'longitude','attributes.Price Range']\n",
    "other_col_prefix = ['Ambience','Good For','Music', 'Parking', 'Dietary Restrictions', 'Hair', 'computed.category.', 'checkin_info']\n",
    "y_col_name = 'stars'\n",
    "gbr = GradientBoostingRegressor(n_estimators=300, max_depth = 8,  verbose=10)\n",
    "eval_res = eval_score(gbr, 'Gradient Boosting', business_checkin, numeric_col_names, other_col_prefix, y_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far the R2 score of 0.2561 is the best we have for predicting a business's star rating using its meta data, and check in info. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
